{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4Jx1MXbRoxueI1PkdhN95",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANDIECOOLER2/YoutubeVideoAnalysis/blob/main/YoutubeAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVhAtldD8Cj8"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "# import re\n",
        "\n",
        "# # Define your niche keywords for topic research\n",
        "# niche_keywords = [\"calisthenics skills\", \"gymnastics rings training\", \"bodyweight strength\", \"advanced push-ups\", \"muscle-ups\"]\n",
        "\n",
        "# # Function to scrape YouTube search results for top-performing videos\n",
        "# def get_top_videos(search_query, max_results=10):\n",
        "#     search_url = f\"https://www.youtube.com/results?search_query={search_query.replace(' ', '+')}\"\n",
        "#     response = requests.get(search_url)\n",
        "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "#     video_data = []\n",
        "#     for video in soup.find_all('a', href=True):\n",
        "#         if '/watch?v=' in video['href']:\n",
        "#             title = video.text.strip()\n",
        "#             link = \"https://www.youtube.com\" + video['href']\n",
        "#             video_data.append({\"title\": title, \"link\": link})\n",
        "#             if len(video_data) >= max_results:\n",
        "#                 break\n",
        "\n",
        "#     return video_data\n",
        "\n",
        "# # Function to extract trending topics from popular videos\n",
        "# def analyze_video_titles(videos):\n",
        "#     topics = []\n",
        "#     for video in videos:\n",
        "#         words = re.findall(r\"\\b\\w+\\b\", video[\"title\"].lower())\n",
        "#         topics.extend(words)\n",
        "\n",
        "#     # Get the most common words used in video titles (excluding stop words)\n",
        "#     common_words = pd.Series(topics).value_counts().head(10)\n",
        "#     return common_words\n",
        "\n",
        "# # Function to analyze thumbnails using OpenAI Vision API (Placeholder for future integration)\n",
        "# def analyze_thumbnails(video_links):\n",
        "#     thumbnail_data = {}\n",
        "#     for link in video_links:\n",
        "#         # Placeholder for thumbnail analysis (e.g., extracting color, text, faces)\n",
        "#         thumbnail_data[link] = \"Analysis Pending\"\n",
        "#     return thumbnail_data\n",
        "\n",
        "# # Scrape top-performing videos for each niche keyword\n",
        "# all_videos = {}\n",
        "# for keyword in niche_keywords:\n",
        "#     videos = get_top_videos(keyword)\n",
        "#     all_videos[keyword] = videos\n",
        "\n",
        "# # Analyze top video titles to find trending topics\n",
        "# trending_topics = {}\n",
        "# for keyword, videos in all_videos.items():\n",
        "#     trending_topics[keyword] = analyze_video_titles(videos)\n",
        "\n",
        "# # Extract video links for thumbnail analysis\n",
        "# video_links = [video[\"link\"] for videos in all_videos.values() for video in videos]\n",
        "# thumbnail_analysis = analyze_thumbnails(video_links)\n",
        "\n",
        "# # Convert results to DataFrame and save for analysis\n",
        "# df_topics = pd.DataFrame(trending_topics)\n",
        "# df_topics.to_csv(\"trending_topics.csv\", index=False)\n",
        "# df_thumbnails = pd.DataFrame(list(thumbnail_analysis.items()), columns=[\"Video Link\", \"Thumbnail Analysis\"])\n",
        "# df_thumbnails.to_csv(\"thumbnail_analysis.csv\", index=False)\n",
        "\n",
        "# print(\"Trending topics and thumbnail analysis complete! Check CSV files for insights.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import googleapiclient.discovery\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Load API key from environment variable\n",
        "youtube_api_key = userdata.get('ytdataAPIKEY')\n",
        "if not youtube_api_key:\n",
        "    raise ValueError(\"Missing YouTube API key. Set the YOUTUBE_API_KEY environment variable.\")\n",
        "\n",
        "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=youtube_api_key)\n",
        "\n",
        "# Define your niche keywords for topic research\n",
        "niche_keywords = [\"calisthenics skills progression\"]\n",
        "\n",
        "# Function to fetch video search results\n",
        "def search_videos(search_query, max_results=10):\n",
        "    request = youtube.search().list(\n",
        "        q=search_query,\n",
        "        part=\"snippet\",\n",
        "        maxResults=max_results,\n",
        "        type=\"video\",\n",
        "        order=\"viewCount\"\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    video_results = []\n",
        "    for item in response.get(\"items\", []):\n",
        "        video_results.append({\n",
        "            \"video_id\": item[\"id\"][\"videoId\"],\n",
        "            \"title\": item[\"snippet\"][\"title\"],\n",
        "            \"channel\": item[\"snippet\"][\"channelTitle\"]\n",
        "        })\n",
        "\n",
        "    return video_results\n",
        "\n",
        "# Function to fetch video statistics in batches\n",
        "def get_video_statistics(video_ids):\n",
        "    stats_request = youtube.videos().list(\n",
        "        part=\"statistics\",\n",
        "        id=\",\".join(video_ids)\n",
        "    )\n",
        "    stats_response = stats_request.execute()\n",
        "\n",
        "    stats_data = {}\n",
        "    for item in stats_response.get(\"items\", []):\n",
        "        stats_data[item[\"id\"]] = {\n",
        "            \"views\": int(item[\"statistics\"].get(\"viewCount\", 0)),\n",
        "            \"likes\": int(item[\"statistics\"].get(\"likeCount\", 0))\n",
        "        }\n",
        "\n",
        "    return stats_data\n",
        "\n",
        "# Function to fetch and store popular videos\n",
        "def fetch_popular_videos():\n",
        "    all_videos = []\n",
        "    for keyword in niche_keywords:\n",
        "        videos = search_videos(keyword)\n",
        "        video_ids = [video[\"video_id\"] for video in videos]\n",
        "\n",
        "        if video_ids:\n",
        "            stats = get_video_statistics(video_ids)\n",
        "\n",
        "            for video in videos:\n",
        "                video_id = video[\"video_id\"]\n",
        "                video[\"views\"] = stats.get(video_id, {}).get(\"views\", 0)\n",
        "                video[\"likes\"] = stats.get(video_id, {}).get(\"likes\", 0)\n",
        "                video[\"link\"] = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "                all_videos.append(video)\n",
        "\n",
        "        time.sleep(1)  # Avoid hitting API rate limits\n",
        "\n",
        "    return all_videos\n",
        "\n",
        "video_data = fetch_popular_videos()\n",
        "\n",
        "# Add timestamp for cache versioning\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "filename = f\"popular_videos_cache_{timestamp}.csv\"\n",
        "\n",
        "df_videos = pd.DataFrame(video_data)\n",
        "df_videos.to_csv(filename, index=False)\n",
        "\n",
        "print(f\"Popular videos data saved for caching: {filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQSL94zwB-xr",
        "outputId": "73a33992-b0ac-4b5f-9389-fe4b75b00acf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Popular videos data saved for caching: popular_videos_cache_20250306-083053.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = zip(list(df_videos[\"title\"]),list(df_videos[\"views\"]),(list(df_videos[\"likes\"])))"
      ],
      "metadata": {
        "id": "DNRdD8vrE9Fq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Title| View | Likes\")\n",
        "for x,y,z in a:\n",
        "  print(x,y,z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSc7ZvdPlugG",
        "outputId": "62a058eb-bb33-4722-9f4c-c33cbee9c248"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title| View | Likes\n",
            "Calisthenics for Beginners | In Depth Step-by-Step Guide to Building Strength and Muscle 5796299 320116\n",
            "Calisthenics for Complete Beginners (Tips, Exercise Form, Programming) 5667975 331273\n",
            "5 Calisthenics Skills Beginners Can Learn at Home (No Equipment) 5489784 240763\n",
            "BEGINNER CALISTHENICS WORKOUT 4217295 199930\n",
            "All Planche Progressions from 0 to Full 3315586 118462\n",
            "Skills that are easier than they look #calisthenics 3281233 215040\n",
            "First what you should learn in Calisthenics | Crow Pose 3232681 0\n",
            "HOW TO MUSCLE UP - THE BEST WAY 2742940 80162\n",
            "How To Full Planche | 10 Steps 2711766 93185\n",
            "10 Steps To Handstand! ðŸ¤¸âœ… 1987409 111271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(df_videos[\"title\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYFsoAGVlgeS",
        "outputId": "6d282cd4-455d-47ce-f38e-83c220a20d83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Calisthenics for Beginners | In Depth Step-by-Step Guide to Building Strength and Muscle',\n",
              " 'Calisthenics for Complete Beginners (Tips, Exercise Form, Programming)',\n",
              " '5 Calisthenics Skills Beginners Can Learn at Home (No Equipment)',\n",
              " 'BEGINNER CALISTHENICS WORKOUT',\n",
              " 'All Planche Progressions from 0 to Full',\n",
              " 'Skills that are easier than they look #calisthenics',\n",
              " 'First what you should learn in Calisthenics | Crow Pose',\n",
              " 'HOW TO MUSCLE UP - THE BEST WAY',\n",
              " 'How To Full Planche | 10 Steps',\n",
              " '10 Steps To Handstand! ðŸ¤¸âœ…']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ideas :-\n",
        "- \"Calisthenics 101: Your Ultimate Beginnerâ€™s Guide to Strength & Skills\"\n",
        "- \"Master the Muscle Up: Step-by-Step Tutorial for Beginners\"\n",
        "- \"5 Easy Calisthenics Moves You Can Master at Home (No Gear Needed!)\"\n",
        "- \"From Zero to Planche: The Complete Progression Guide\"\n",
        "- \"Handstand Made Simple: 10 Steps for Beginners to Nail It\"\n",
        "- \"Crow Pose Crash Course: The First Calisthenics Skill You Need to Learn\"\n",
        "- \"Beginner Calisthenics Workout: Build Muscle Without a Gym\"\n",
        "- \"Top Calisthenics Skills That Look Hard But Are Easier Than You Think\"\n",
        "- \"How to Start Calisthenics: Tips, Tricks, and a Full Routine\"\n",
        "- \"Planche for Beginners: 10 Steps to Unlock This Epic Skill\""
      ],
      "metadata": {
        "id": "15lGVu0bmU3J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ivbMelPzmUT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import googleapiclient.discovery\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Load API key from environment variable\n",
        "youtube_api_key = userdata.get('ytdataAPIKEY')\n",
        "if not youtube_api_key:\n",
        "    raise ValueError(\"Missing YouTube API key. Set the YOUTUBE_API_KEY environment variable.\")\n",
        "\n",
        "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=youtube_api_key)\n",
        "\n",
        "# Define your niche keywords for topic research\n",
        "niche_keywords = [\"calisthenics skills progression\"]\n",
        "\n",
        "# Function to fetch video search results\n",
        "def search_videos(search_query, max_results=10):\n",
        "    request = youtube.search().list(\n",
        "        q=search_query,\n",
        "        part=\"snippet\",\n",
        "        maxResults=max_results,\n",
        "        type=\"video\",\n",
        "        order=\"viewCount\"\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    video_results = []\n",
        "    for item in response.get(\"items\", []):\n",
        "        video_results.append({\n",
        "            \"video_id\": item[\"id\"][\"videoId\"],\n",
        "            \"title\": item[\"snippet\"][\"title\"],\n",
        "            \"channel\": item[\"snippet\"][\"channelTitle\"]\n",
        "        })\n",
        "\n",
        "    return video_results\n",
        "\n",
        "# Function to fetch video statistics in batches\n",
        "def get_video_statistics(video_ids):\n",
        "    stats_request = youtube.videos().list(\n",
        "        part=\"statistics\",\n",
        "        id=\",\".join(video_ids)\n",
        "    )\n",
        "    stats_response = stats_request.execute()\n",
        "\n",
        "    stats_data = {}\n",
        "    for item in stats_response.get(\"items\", []):\n",
        "        stats_data[item[\"id\"]] = {\n",
        "            \"views\": int(item[\"statistics\"].get(\"viewCount\", 0)),\n",
        "            \"likes\": int(item[\"statistics\"].get(\"likeCount\", 0))\n",
        "        }\n",
        "\n",
        "    return stats_data\n",
        "\n",
        "# Function to fetch and store popular videos\n",
        "def fetch_popular_videos_and_create_csv():\n",
        "\n",
        "    for keyword in niche_keywords:\n",
        "        videos = search_videos(keyword)\n",
        "        video_ids = [video[\"video_id\"] for video in videos]\n",
        "        all_videos = []\n",
        "        if video_ids:\n",
        "            stats = get_video_statistics(video_ids)\n",
        "\n",
        "            for video in videos:\n",
        "                video_id = video[\"video_id\"]\n",
        "                video[\"views\"] = stats.get(video_id, {}).get(\"views\", 0)\n",
        "                video[\"likes\"] = stats.get(video_id, {}).get(\"likes\", 0)\n",
        "                video[\"link\"] = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "                all_videos.append(video)\n",
        "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "        filename = f\"popular_videos_on_{keyword}_cache_{timestamp}.csv\"\n",
        "\n",
        "        df_videos = pd.DataFrame(all_videos)\n",
        "        df_videos.to_csv(filename, index=False)\n",
        "\n",
        "        time.sleep(1)  # Avoid hitting API rate limits\n",
        "\n",
        "    print(\"ALL DATA CREATED IN CSV\")\n",
        "\n",
        "\n",
        "fetch_popular_videos_and_create_csv()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXNx1OOjFMZq",
        "outputId": "88c9b648-fc75-41b5-c004-73fbe9169308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALL DATA CREATED IN CSV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embed Vectors and Train Model\n",
        "#### Note the below code is AI generated to get you started lol don't rely on it to be right\n",
        "###### Use Reference\n",
        "\n",
        "[Reference: handson-ml3  ](https://github.com/ageron/handson-ml3)"
      ],
      "metadata": {
        "id": "JJnSi0EDY9Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "#\n",
        "############################\n",
        "#HERE USE ML SKILLS AND SEE IF YOU CAN GET A AWESOME OR WELL REPRESENTED METRIC, TRY PCA AND OTHER DIMENSIONALITY REDUCTION\n",
        "#   to get useful insights\n",
        "#################\n",
        "def rank_videos(df):\n",
        "    \"\"\"\n",
        "    Rank videos based on weighted formula: 0.7 * views + 0.3 * likes\n",
        "    \"\"\"\n",
        "    df[\"score\"] = 0.7 * df[\"views\"] + 0.3 * df[\"likes\"]\n",
        "    return df.sort_values(by=\"score\", ascending=False)\n",
        "\n",
        "######\n",
        "###HERE USE OLLMA NOMIC EMBEDDING, HAVE TO RUN IT LOCALLY AND MAKE API CALLS\n",
        "#######\n",
        "def embed_titles(df, model_name=\"all-MiniLM-L6-v2\"):\n",
        "    \"\"\"\n",
        "    Convert video titles into embeddings using a Sentence Transformer model.\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer(model_name)\n",
        "    df[\"embedding\"] = df[\"title\"].apply(lambda x: model.encode(x).tolist())\n",
        "    return df\n",
        "\n",
        "###\n",
        "### Here you need to use your skills and see best model architecture\n",
        "### GAN is outdated and takes time to train\n",
        "###\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim=32):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, latent_dim * 2)  # Mean and log-variance\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc_out = self.encoder(x)\n",
        "        mu, logvar = enc_out.chunk(2, dim=-1)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decoder(z), mu, logvar\n",
        "\n",
        "def train_vae(df, epochs=10, batch_size=32, latent_dim=32):\n",
        "\n",
        "###\n",
        "##SEE IF YOU CAN USE TF DATA API OR OTHER DATA PREPROCSSING APIs for faster load and traiining times, see refernce\n",
        "###\n",
        "    features = torch.tensor(df[[\"views\", \"likes\", \"score\"]].values, dtype=torch.float32)\n",
        "    embeddings = torch.tensor(df[\"embedding\"].tolist(), dtype=torch.float32)\n",
        "    X = torch.cat((features, embeddings), dim=1)\n",
        "\n",
        "    dataset = TensorDataset(X)\n",
        "    ##TRY TO MAKE THIS COmpataible with dataloading api and also youtube data api\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    input_dim = X.shape[1]\n",
        "    vae = VAE(input_dim, latent_dim)\n",
        "    optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch in dataloader:\n",
        "            x = batch[0]\n",
        "            recon_x, mu, logvar = vae(x)\n",
        "            loss = loss_fn(recon_x, x)  # Simple MSE loss for reconstruction\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "\n",
        "    return vae\n",
        "\n",
        "# Example Usage:\n",
        "if __name__ == \"__main__\": # this is not required we are running in colab or notebook\n",
        "    sample_data = {\n",
        "        \"title\": [\"Tech Review\", \"AI Breakthrough\", \"Python Tips\"],\n",
        "        \"views\": [50000, 120000, 80000],\n",
        "        \"likes\": [5000, 8000, 6000]\n",
        "    }\n",
        "    df = pd.DataFrame(sample_data) # here we have data from youtube\n",
        "    df = rank_videos(df)\n",
        "    df = embed_titles(df)\n",
        "    vae_model = train_vae(df)\n"
      ],
      "metadata": {
        "id": "eBf3HCvuIIDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779bcdf2-c8eb-4a91-a015-ea830a415660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VejvSBvKaHKq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}